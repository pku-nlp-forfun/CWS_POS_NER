
\subsection{Part-of-speech Tagging}
\label{sec:pos}

目前我们所使用的词性标注，基本上都是以「假设数据集正确」来做的，为了更好的符合数据集的结果，我们将数据集进行分析，并且建立一个简易的知识图谱来做词与词性之间的对应。

我们发现一些棘手的例子，在数据集中，有很多数据会有多种词性标注，故我们倾向于预测数据集中出现最多的那种词性。因为若用模型来预测很容易被误导而训练出很差的效果，所以牺牲一部分「错误的正确性」算是相对合理的。

最原始模型基于所有见过的词进行出现频率上的统计，这在撇除分词效果（直接将 gold 分词结果读入当做模型输入），就可以直接达到95\%左右的准确度。我们倾向于预测所有没出现过的词为名词，毕竟专有名词经过我们统计是最有可能没有出现过的。由于因为输入之分词与评价的集合完全相同，这相当于计算 precision 和 recall 的分母相同，故 precision、recall、f1-score 会呈现完全相同的结果。

之后基于此模型在加上规则，这在数据很脏的时候特别有效，毕竟很多在词性标注的标准中，我们课堂使用的标准特别的「特殊」，所以若尝试使用外部标准，反而会使效果下降，而若使用机器学习，则会「教坏」它。随著规则的增多，提高了几个百分点，毕竟原先的效果已经很好了。
