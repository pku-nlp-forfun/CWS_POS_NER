\section{实验分工及感想}
\label{sec:conclusion}

一开始也没有太特别的分工，主要先阅读一些相关的论文以及逐行研究目前流行之分词工具的底层源代码来收集灵感，接著一起决定要使用什么样的模型、使用哪些 library，并且拟定大方向架构。后来因为我们这学期修了太多扎实的课，包含数门信科的自然语言处理课程，导致时间被压缩的很紧迫，故决定并行动工，由姜慧强实现分词、李大为来做预处理与实现词性标注。相关工作细节皆公开透明开源于 \fnurl{Github}{https://github.com/pku-nlp-forfun/CWS_POS_NER} 上。

因为实验数据中噪音比较大，另外在校对F1score过程中浪费了一些时间。由于数据基本上已经脏到不能当做一般数据来使用，也不可能找其他数据集来训练，因为所基于的标准完全不同，也没有很多特有的东西，比如"\$\$\_"之类的东西。所以一旦想要追求模型表现，那就不可能做出能通用于其他语料的版本。那我们最后决定主要倾向针对本次任务进行优化，并且不使用任何外部数据。但由于数据量对于模型训练还是偏少，故过度的追求模型表现只是纯粹的自我打击，也让我们学会了，如果是任务结果导向，能跳脱机器学习的迷思也许才是其中的关键，仔细去看结巴分词的实现，里面也有很多正则表达式，毕竟并不是所有任务、数据都适合机器学习。

在实验过程中，加强了对CRF、概率图模型的认识，提高了动手时间能力，强化了对Trick的使用，对个人实践能力有较高的帮助。

另外在实践过程中遇到一些挫折，当然这些挫折原因多种多样，我们还是想尽可能用更科学的方式，更严谨的态度来完成这次实验。