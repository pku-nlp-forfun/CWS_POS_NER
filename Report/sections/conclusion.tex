\section{实验分工及感想}
\label{sec:conclusion}

一开始也没有太特别的分工，主要先阅读一些相关的论文以及逐行研究目前流行之分词工具的底层源代码来收集灵感，接著一起决定要使用什么样的模型、使用哪些 library，并且拟定大方向架构。后来因为我们这学期修了太多扎实的课，包含数门信科的自然语言处理课程，导致时间被压缩的很紧迫，故决定并行动工，由姜慧强实现分词、李大为来做预处理与实现词性标注。相关工作细节皆公开透明开源于 \fnurl{Github}{https://github.com/pku-nlp-forfun/CWS_POS_NER} 上。

由于所提供的数据与评测脚本实在太过于草率，故在实作时姜慧强也花了很多时间校正了评测脚本，让在训练模型时不致于被错误的指标误导而往错误的方向优化。由于数据基本上已经脏到不能当做一般数据来使用，也不可能找其他数据集来训练，因为所基于的标准完全不同，也没有很多特有的东西，比如"\$\$\_"之类的东西。所以一旦想要追求模型表现，那就不可能做出能通用于其他语料的版本。那我们最后决定主要倾向针对本次任务进行优化，并且不使用任何外部数据。但由于数据量对于模型训练还是偏少，故过度的追求模型表现只是纯粹的自我打击，也让我们学会了，如果是任务结果导向，能跳脱机器学习的迷思也许才是其中的关键，仔细去看结巴分词的实现，里面也有很多正则表达式，毕竟并不是所有任务、数据都适合机器学习。

在第一次作业时，我们两个人都是被选进前十佳作业中的，毕竟上课听完同学报告，准确度高的没有一个不是手动进去人工调，大概只有少数几个人是跟我们一样纯写通用规则和自定义辞典的吧。这也是做作业越作越挫折的原因吧，努力无法与成绩成正比，写再多行脚本也比不上针对数据蛮干的，大致上是这两次下来的心得。